The text explains the complexity of existing systems, particularly in the context of SAP ERP systems. It highlights how sales order processing and other operations require updates to multiple tables, including basic tables, index tables, and aggregate tables. The need for these tables arises because dynamically calculating data from the base tables is expensive and time-consuming. As a result, SAP maintains various index and aggregate tables to optimize data retrieval, despite the redundancy and increased complexity this introduces. The text also points out that the proliferation of these tables leads to a large number of database tables, making data extraction and management more complicated.

The text discusses the complexity introduced by maintaining various index and aggregate tables in a database system. Here's a step-by-step explanation:

1. Index and Aggregate Tables:

    - Index Tables: These are special tables that help speed up data retrieval operations. They work like an index in a book, allowing the database to quickly locate the data without scanning the entire table.
    - Aggregate Tables: These tables store precomputed results of complex queries, such as sums, averages, or counts. They help in quickly retrieving aggregated data without recalculating it every time.

2. Optimization vs. Complexity:

    - While these tables optimize data retrieval by making it faster and more efficient, they also introduce redundancy. Redundancy means that the same data might be stored in multiple places, which can lead to inconsistencies if not managed properly.
    - The increased number of tables adds to the complexity of the database system. More tables mean more maintenance, more potential for errors, and more complicated data management.

3. Proliferation of Tables:

    - The text mentions that the proliferation (rapid increase) of these tables leads to a large number of database tables. This makes data extraction and management more complicated because:
        - Developers and database administrators have to keep track of many tables.
        - Queries might need to join multiple tables, which can be complex and error-prone.
        - Updating data might require changes in multiple tables to keep everything consistent.

4. Example of Sales Order Processing:

    -    When a sales order is created, several basic tables are updated. These tables might include:
        - Order Header Table: Contains general information about the order, such as order number, date, customer information, etc.
        - Order Line-Item Table: Contains details about each item in the order, such as product ID, quantity, price, etc.
    - The text suggests that similar structures exist for other types of orders, such as production orders in manufacturing systems. These orders also have header data and line-item data, along with scheduling data.

5. Complexity in Different Systems:

    -    The text briefly touches on different systems like MM (Materials Management) and PP (Production Planning) in an ERP (Enterprise Resource Planning) system. Each of these systems has its own set of tables and data structures, adding to the overall complexity.

In summary, while index and aggregate tables are essential for optimizing data retrieval, they also introduce redundancy and complexity. Managing a large number of tables requires careful planning and maintenance to ensure data consistency and efficient operations. The example of sales order processing illustrates how multiple tables are involved in even a single business process, highlighting the intricate nature of database systems.






The provided text discusses the complexity of existing ERP systems, particularly focusing on the example of sales order processing. When a sales order is created, several basic tables are updated, such as those containing order data, sales data, and other related information. For instance, in a production order, there are tables for header data, item data, and scheduling data. Similarly, in materials management (MM), there are tables for order header data, line-item data, partner data, and so forth.

On top of these basic tables, SAP also updates index tables to optimize data retrieval. For example, there is an index table for orders by material, which allows users to quickly view all orders for a particular material. However, creating and maintaining these index tables is resource-intensive. The text explains that dynamically calculating data from the basic tables is an expensive operation, so SAP preemptively updates index tables to improve performance.

The text also mentions the use of aggregate tables, which store cumulative data to avoid expensive dynamic calculations. For example, in credit management, tables like S066 and S067 store cumulative open order quantities and open delivery quantities, respectively. These tables are updated in parallel with the creation of orders to facilitate quick access to aggregated data.

The author highlights that this approach leads to redundancy, as the same data is stored in multiple tables in different formats. This redundancy results in a significant increase in the number of tables, making the system more complex and harder to maintain. The text points out that a standard SAP ERP system can have close to 100,000 tables, including around 15,000 to 20,000 index tables. This complexity arises because the current database techniques, such as those used in Oracle, Microsoft SQL, and Sybase, require extensive indexing and aggregation to ensure efficient data retrieval.

In summary, the text explains that the complexity of existing ERP systems is primarily due to the need for numerous index and aggregate tables. These tables are necessary to optimize performance but result in a highly complex and redundant system landscape. This complexity makes development and maintenance challenging and costly.





Let's take an example of sales order processing when you create a sales order the basic tables updated

the examples of basic tables are we being the same order that we be the sales like them and then so

on and so forth.

If you order from a m m or Peepy Bagnold think of a production order production order has some header

data item B scheduling data centers or same thing with M M M M which is order as head of data Line-Item

data partner data source and so forth.

Right.

So these are the basic rules that are built in.

So far so good.

On top of that Sep also updates the index dibbles

example we in the this table is called orders by.

So if somebody wants to view all the orders for a particular material you can go to the BHP a key and

grab those.

But it's a very expensive operation.

So right at the time of creating the order is maybe a bit this index table we APM that's optimized all

the data of orders by material.

That's why they're called Indic steepens.

Another example we keep the orders by partners give me all the orders for Wal-Mart.

Again you can grab them from B A B B B.

All those best apples.

But again it's an expensive operation so he knows that pulling orders by partners or materials is an

expensive operation.

Number one and number two these are required operations.

They are required because they know that these reports have been pulled.

Since you had the system started so they have delivered all of them by before and whenever an order

is created these entries are made.

What is the more examples in-law stable's

if you have done credit management in sales or the processing you know that s 0 6 6 this is an example

of open order cumulative What's the portal open order quantity.

What up my at Kostova.

You can grab them again from PBK by aggregating all those tables but all those rules and then saying

OK this is how much they have on it.

But no that's an expensive operation.

So Sep in parallel makes an entry and update as 0 6 x table with the open order cumulative quantity.

Same thing with as 0 6 7 this is opened INTUITY million same thing cumulative Why are these used to

calculate the credit that has been consumed by a customer Boogaloo open credit and don't open orders

open delivery open billing and that's being compared against the open items and the credit limits on

and so forth.

There's the whole business logic that happens

where does the point.

The point is the entry is made in these tables or because dynamically calculating the open items from

VBH key is an expensive operation.

So I have the time of creating these orders or building these orders.

All these tables need to be updated.

We want more examples Nipsy there are still Dubos these tables exist in every functional area as the

imam Delphi CRM the in sales that a b b b b b b had on a level state basis Item 11 status is still does

this of simple things like has the order been delivered has the order been buried.

In it and that is a building this day needs to be updated to be in it and the delivery has happened.

This table needs to be updated to deliver against the corresponding.

And then we have to do lists right.

That also part of indexes like delivery do list billing do list billing do list could be part of material

by shipping point and then we have open data like in SD all ports need to be stored in the table in

SD.

So this is how the index tables allow a stable state to stabilize or updated for every single order

that looks good.

In no in M-M.

If you take the medieval document that is a medieval document of him he yeah right then am sick.

These are material documents where desert and the

there are so many index tables history tables aggregate tables valuation based tables for example in

history you rate something modded itch a history table what changes have happened to this document.

Hobo tokens in me a b a b and then valuation.

B E W d w a hedge and then that an index tables.

Again what is the point.

The point is the same data that's in here is being repeated in these tables only on an aggregate basis

meaning what is the portal value of medieval documents.

My plan is the location that is being stored here.

Where did the total evaluation that's being stored here.

If you go to the sales are processing all this data is mostly changes happening to the best it was some

change happen.

Here you go a these debates and these are hard typically aggregate is where I can get.

Now if you compare the basic table let's say the basic tables are five tables and since on a processing

the aggregate tables are 100 or 500 the actual data resides here.

This is the basic data just because we are not able to read drive that data in time with the current

database techniques we are doing so much of aggregation and writing so many redundant aggregate people

it's the same set of data just being repeated again and again and again because we want the data in

that format.

It's like Play-Doh.

This is your original Pleydell.

And then these are all variations you can make many shapes sort of Play-Doh.

Right.

But the original material is the same.

Any change of the additional material is being recorded in the original tables or original structures

and then all these changes need to be replicated and propagated to these aggregate tables.

And this is the primary cause of all the devlopment complexity.

This is where the problem starts.

And because of these aggregate tables this results in huge and putting it in capital letters huge database

tables if you go to your ERP system standard Sep ERP system that are close to a hundred thousand a little

less than that transporting people.

I'm not talking structures not talking any of that stuff.

The basic transport and tables that are 100000 of them.

Can you believe that Besant ERP system really need 100000 tables because of the aggregates down it's

become so complicated.

There are so many tables that I've acquired Wicca's extracting data or meaning for data from the base

tables is complicated using the current database techniques like Oracle Microsoft sequel Sybase on and

on these tables.

There are probably 15 to 20000 index tables.

What is it index.

Let me show you some examples of these deep.

All right.

If they go to a table like VB AK which is the standard essay be some sort of a b b b a b.

So if you are an MMO or Peepy consultant you can imagine the standard head an item.

Put on display.

Then go to indexes

and you'll see that for people that are so many different excuses index on this column index on a group

of columns sort of why have this index differs.

Why does a pebble like a sales sort of head.

For example how indexes are in business by the way these are all credible numbers.

You know you can just go to the tables behind the scenes.

For example if you want to look at the list of database tables you can go do something like 0 2 0 2

L is a table and then search for all the list of peoples.

Same thing with indexes or indices that are tables where all the indices are stored.

So you can just go verify that these are real numbers almost close.

Or just maybe rounded some of them but they're very close.

So coming back to our question why do we need index tables.